{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integer, Categorical, Real\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier \u001b[38;5;28;01mas\u001b[39;00m CuMLRandomForestClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC \u001b[38;5;28;01mas\u001b[39;00m CuMLSVC\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VotingClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Categorical, Real\n",
    "from cuml.ensemble import RandomForestClassifier as CuMLRandomForestClassifier\n",
    "from cuml.svm import SVC as CuMLSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a smaller subset for initial testing\n",
    "SUBSET_SIZE = 5000  # Adjust this value as needed\n",
    "logger.info(f\"Using subset of {SUBSET_SIZE} samples for testing\")\n",
    "X_train = X_train[:SUBSET_SIZE]\n",
    "y_train = y_train[:SUBSET_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and scale the data using CuPy for GPU acceleration\n",
    "logger.info(\"Preprocessing data...\")\n",
    "X_train = cp.asarray(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test = cp.asarray(X_test.reshape(X_test.shape[0], -1))\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.get())\n",
    "X_test_scaled = scaler.transform(X_test.get())\n",
    "\n",
    "# Convert to CuPy arrays for GPU processing\n",
    "X_train_scaled = cp.asarray(X_train_scaled)\n",
    "X_test_scaled = cp.asarray(X_test_scaled)\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Full Hyperparameter Search Spaces\n",
    "# rf_param_grid = {\n",
    "#     \"n_estimators\": Integer(50, 500),\n",
    "#     \"criterion\": Categorical([\"gini\", \"entropy\"]),\n",
    "#     \"max_depth\": Categorical([None, 3, 5, 10, 20, 30]),\n",
    "#     \"min_samples_leaf\": Integer(1, 16),\n",
    "#     \"max_features\": Categorical([\"sqrt\", \"log2\", 0.25, 0.5]),\n",
    "#     \"bootstrap\": Categorical([True, False]),\n",
    "#     \"min_samples_split\": Integer(2, 10),\n",
    "#     \"class_weight\": Categorical([None, \"balanced\", \"balanced_subsample\"]),\n",
    "# }\n",
    "\n",
    "# svm_param_grid = {\n",
    "#     \"C\": Real(1e-4, 1e3, \"log-uniform\"),\n",
    "#     \"kernel\": Categorical([\"linear\", \"rbf\", \"poly\", \"sigmoid\"]),\n",
    "#     \"gamma\": Categorical([\"scale\", \"auto\"] + [0.001, 0.01, 0.1, 1, 10]),\n",
    "#     \"degree\": Integer(2, 4),\n",
    "#     \"coef0\": Real(0.0, 1.0),\n",
    "#     \"class_weight\": Categorical([None, \"balanced\"]),\n",
    "# }\n",
    "\n",
    "# ensemble_param_grid = {\n",
    "#     \"voting\": Categorical([\"soft\", \"hard\"]),\n",
    "#     \"weights\": Categorical([None, (0.5, 0.5), (0.3, 0.7), (0.7, 0.3)]),\n",
    "#     \"rf__n_estimators\": Integer(100, 300),\n",
    "#     \"rf__max_depth\": Categorical([None, 10, 20]),\n",
    "#     \"svm__C\": Real(0.1, 10, \"log-uniform\"),\n",
    "#     \"svm__gamma\": Categorical([\"scale\", \"auto\", 0.01]),\n",
    "# }\n",
    "\n",
    "# Reduced Testing Version\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": Integer(50, 100),\n",
    "    \"max_depth\": Categorical([10, 20]),\n",
    "    \"min_samples_split\": Integer(2, 5),\n",
    "    \"max_features\": Categorical([\"sqrt\"]),\n",
    "}\n",
    "\n",
    "svm_param_grid = {\n",
    "    \"C\": Real(0.1, 1.0, \"log-uniform\"),  \n",
    "    \"kernel\": Categorical([\"rbf\"]),       \n",
    "    \"gamma\": Categorical([\"scale\"]),      \n",
    "}\n",
    "\n",
    "ensemble_param_grid = {\n",
    "    \"voting\": Categorical([\"soft\"]),              \n",
    "    \"weights\": Categorical([None]),                \n",
    "    \"rf__n_estimators\": Integer(50, 100),        \n",
    "    \"rf__max_depth\": Categorical([10]),          \n",
    "    \"svm__C\": Real(0.1, 0.5, \"log-uniform\"),     \n",
    "    \"svm__gamma\": Categorical([\"scale\"]),         \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmBayesSearchCV(BayesSearchCV):\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        with tqdm(total=self.n_iter, desc=\"Bayesian optimization\") as pbar:\n",
    "            def wrapped_evaluate(candidate_params):\n",
    "                start_time = datetime.now()\n",
    "                logger.info(f\"Testing parameters: {candidate_params}\")\n",
    "                result = evaluate_candidates(candidate_params)\n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).total_seconds()\n",
    "                logger.info(f\"Iteration completed in {duration:.2f} seconds\")\n",
    "                pbar.update(1)\n",
    "                return result\n",
    "            return super()._run_search(wrapped_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tune Random Forest (cuML)\n",
    "# rf = cuRF(random_state=42)\n",
    "# bayes_search_rf = BayesSearchCV(estimator=rf, search_spaces=rf_param_grid, cv=3, random_state=42) \n",
    "# bayes_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Tune Random Forest with CuML RandomForest\n",
    "rf = CuMLRandomForestClassifier(random_state=42)\n",
    "bayes_search_rf = TqdmBayesSearchCV(estimator=rf, search_spaces=rf_param_grid, cv=3, n_jobs=-1, random_state=42, verbose=3)\n",
    "bayes_search_rf.fit(X_train_scaled.get(), y_train)\n",
    "print(\"Best Random Forest (BayesSearch) Hyperparameters:\", bayes_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tune SVM (cuML)\n",
    "# svm = cuSVC(probability=True, random_state=42)\n",
    "# bayes_search_svm = BayesSearchCV(estimator=svm, search_spaces=svm_param_grid, cv=3, random_state=42) \n",
    "# bayes_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Tune SVM with CuML SVC \n",
    "svm = CuMLSVC(probability=True, random_state=42)\n",
    "bayes_search_svm = TqdmBayesSearchCV(estimator=svm, search_spaces=svm_param_grid, cv=3, n_jobs=-1, random_state=42, verbose=3)\n",
    "bayes_search_svm.fit(X_train_scaled.get(), y_train)\n",
    "print(\"Best SVM (BayesSearch) Hyperparameters:\", bayes_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base models with best individual parameters\n",
    "best_rf = CuMLRandomForestClassifier(**bayes_search_rf.best_params_, random_state=42)\n",
    "best_svm = CuMLSVC(**bayes_search_svm.best_params_, probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base ensemble model with best individual parameter models \n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('svm', best_svm)],\n",
    "    voting='soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tuning Ensemble \n",
    "# bayes_search_ensemble = BayesSearchCV(estimator=ensemble, search_spaces=ensemble_param_grid, cv=3, n_jobs=-1, random_state=42)\n",
    "# bayes_search_ensemble.fit(X_train_scaled, y_train)\n",
    "# print(\"Best Ensemble (BayesSearch) Hyperparameters:\", bayes_search_ensemble.best_params_) \n",
    "\n",
    "# Tuning Ensemble\n",
    "bayes_search_ensemble = TqdmBayesSearchCV(estimator=ensemble, search_spaces=ensemble_param_grid, cv=3, n_jobs=-1, random_state=42, verbose=3)\n",
    "bayes_search_ensemble.fit(X_train_scaled.get(), y_train)\n",
    "print(\"Best Ensemble (BayesSearch) Hyperparameters:\", bayes_search_ensemble.best_params_) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_test_bin = LabelBinarizer().fit_transform(\n",
    "        cp.asnumpy(y_test)\n",
    "    )  # Use LabelBinarizer, convert CuPy to NumPy for plotting\n",
    "    pred = cp.asnumpy(model.predict(X_test))  # Convert Cupy to Numpy\n",
    "    accuracy = accuracy_score(cp.asnumpy(y_test), pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_score = cp.asnumpy(model.predict_proba(X_test))  # Convert Cupy to Numpy\n",
    "    plot_roc_curve(y_test_bin, y_score)\n",
    "    plot_confusion_matrix(cp.asnumpy(y_test), pred)  # Convert CuPy to NumPy here\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_test_bin, y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(10):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(10):\n",
    "        plt.plot(fpr[i], tpr[i], label=\"Class {} (AUC = {:.2f})\".format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, pred):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=range(10),\n",
    "        yticklabels=range(10),\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- SVM (Best from BayesSearch) ---\")\n",
    "evaluate_model(bayes_search_svm.best_estimator_, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Random Forest (Best from BayesSearch) ---\")\n",
    "evaluate_model(bayes_search_rf.best_estimator_, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Ensemble Model (Best from BayesSearch) ---\")\n",
    "evaluate_model(bayes_search_ensemble.best_estimator_, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
