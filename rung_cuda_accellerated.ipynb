{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from skopt import BayesSearchCV\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.svm import SVC as cuSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape, scale, and convert to CuPy\n",
    "X_train = X_train.reshape(50000, 3072).astype(np.float32)\n",
    "X_test = X_test.reshape(10000, 3072).astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = cp.asarray(X_train_scaled)\n",
    "X_test_scaled = cp.asarray(X_test_scaled)\n",
    "y_train = cp.asarray(y_train.flatten())\n",
    "y_test = cp.asarray(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter search spaces\n",
    "# rf_param_grid = {\n",
    "#     \"n_estimators\": [50, 100, 200, 300, 500],\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\": [None, 3, 5, 10, 20, 30],\n",
    "#     \"min_samples_leaf\": [1, 2, 4, 8, 16],\n",
    "#     \"max_features\": [\"sqrt\", \"log2\", 0.25, 0.5],\n",
    "#     \"bootstrap\": [True, False],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "#     \"class_weight\": [None, \"balanced\", \"balanced_subsample\"],\n",
    "# }\n",
    "# svm_param_grid = {\n",
    "#     \"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#     \"kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "#     \"gamma\": [\"scale\", \"auto\", 0.001, 0.01, 0.1, 1, 10],\n",
    "#     \"degree\": [2, 3, 4],\n",
    "#     \"coef0\": [0.0, 0.1, 0.5, 1],\n",
    "#     \"class_weight\": [None, \"balanced\"],\n",
    "# }\n",
    "\n",
    "# # Ensemble hyperparameter search space\n",
    "# ensemble_param_grid = {\n",
    "#     \"voting\": [\"soft\", \"hard\"],\n",
    "#     \"weights\": [None, [0.5, 0.5], [0.3, 0.7], [0.7, 0.3]],\n",
    "#     \"rf__n_estimators\": [100, 200, 300],\n",
    "#     \"rf__max_depth\": [None, 10, 20],\n",
    "#     \"svm__C\": [0.1, 1, 10],\n",
    "#     \"svm__gamma\": [\"scale\", \"auto\", 0.01],\n",
    "# }\n",
    "\n",
    "# Hyperparameter search spaces (Reduced for faster testing)\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"max_features\": [\"sqrt\", 0.5],\n",
    "}\n",
    "\n",
    "svm_param_grid = {\n",
    "    \"C\": [0.1, 1, 10],\n",
    "    \"kernel\": [\"linear\", \"rbf\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "ensemble_param_grid = {\n",
    "    \"voting\": [\"soft\", \"hard\"],\n",
    "    \"weights\": [None, [0.5, 0.5]],\n",
    "    \"rf__n_estimators\": [100, 200], \n",
    "    \"rf__max_depth\": [None, 10],\n",
    "    \"svm__C\": [0.1, 1],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tune Random Forest (cuML)\n",
    "# rf = cuRF(random_state=42)\n",
    "# bayes_search_rf = BayesSearchCV(estimator=rf, search_spaces=rf_param_grid, cv=3, random_state=42) \n",
    "# bayes_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Tune Random Forest (reduced iterations for testing)\n",
    "rf = cuRF(random_state=42)\n",
    "bayes_search_rf = BayesSearchCV(estimator=rf, search_spaces=rf_param_grid, cv=3, random_state=42, n_iter=15) \n",
    "bayes_search_rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tune SVM (cuML)\n",
    "# svm = cuSVC(probability=True, random_state=42)\n",
    "# bayes_search_svm = BayesSearchCV(estimator=svm, search_spaces=svm_param_grid, cv=3, random_state=42) \n",
    "# bayes_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Tune SVM (reduced iterations for testing)\n",
    "svm = cuSVC(probability=True, random_state=42)\n",
    "bayes_search_svm = BayesSearchCV(estimator=svm, search_spaces=svm_param_grid, cv=3, random_state=42, n_iter=15) # n_iter reduced\n",
    "bayes_search_svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base models with best individual parameters\n",
    "best_rf = cuRF(**bayes_search_rf.best_params_, random_state=42)\n",
    "best_svm = cuSVC(**bayes_search_svm.best_params_, probability=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base ensemble model with best individual parameter models \n",
    "ensemble = Pipeline([\n",
    "    (\"voting\", VotingClassifier(estimators=[('rf', best_rf), ('svm', best_svm)]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tuning Ensemble \n",
    "# bayes_search_ensemble = BayesSearchCV(estimator=ensemble, search_spaces=ensemble_param_grid, cv=3, n_jobs=-1, random_state=42)\n",
    "# bayes_search_ensemble.fit(X_train_scaled, y_train)\n",
    "# print(\"Best Ensemble (BayesSearch) Hyperparameters:\", bayes_search_ensemble.best_params_) \n",
    "\n",
    "# Tuning Ensemble (Reduced iterations for testing)\n",
    "bayes_search_ensemble = BayesSearchCV(estimator=ensemble, search_spaces=ensemble_param_grid, cv=3, n_jobs=-1, random_state=42, n_iter=15)\n",
    "bayes_search_ensemble.fit(X_train_scaled, y_train)\n",
    "print(\"Best Ensemble (BayesSearch) Hyperparameters:\", bayes_search_ensemble.best_params_) \n",
    "\n",
    "best_ensemble = bayes_search_ensemble.best_estimator_[\"voting\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_test_bin = LabelBinarizer().fit_transform(\n",
    "        cp.asnumpy(y_test)\n",
    "    )  # Use LabelBinarizer, convert CuPy to NumPy for plotting\n",
    "    pred = cp.asnumpy(model.predict(X_test))  # Convert Cupy to Numpy\n",
    "    accuracy = accuracy_score(cp.asnumpy(y_test), pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    y_score = cp.asnumpy(model.predict_proba(X_test))  # Convert Cupy to Numpy\n",
    "    plot_roc_curve(y_test_bin, y_score)\n",
    "    plot_confusion_matrix(cp.asnumpy(y_test), pred)  # Convert CuPy to NumPy here\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_test_bin, y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(10):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(10):\n",
    "        plt.plot(fpr[i], tpr[i], label=\"Class {} (AUC = {:.2f})\".format(i, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, pred):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=range(10),\n",
    "        yticklabels=range(10),\n",
    "    )\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- SVM (Best from BayesSearch) ---\")\n",
    "evaluate_model(bayes_search_svm.best_estimator_, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Random Forest (Best from BayesSearch) ---\")\n",
    "evaluate_model(bayes_search_rf.best_estimator_, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Ensemble Model (Best from BayesSearch) ---\")\n",
    "evaluate_model(best_ensemble, X_test_scaled, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
