{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_layer_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"dBt2A2pghKZw","colab_type":"code","outputId":"dc58ac3c-33a8-49b4-cb8f-9bebcba1c947","executionInfo":{"status":"ok","timestamp":1543782254454,"user_tz":360,"elapsed":5332,"user":{"displayName":"Christine Phan","photoUrl":"","userId":"17719443631378856614"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"cell_type":"code","source":["!pip install keras_sequential_ascii"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras_sequential_ascii\n","  Downloading https://files.pythonhosted.org/packages/2d/a4/806e3ed5d7ac7463e2fae77e09ccccc88c78266b248fb637e4efa4f65ec0/keras_sequential_ascii-0.1.1.tar.gz\n","Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_sequential_ascii) (2.2.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (2.8.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.14.6)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.0.5)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.0.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.11.0)\n","Building wheels for collected packages: keras-sequential-ascii\n","  Running setup.py bdist_wheel for keras-sequential-ascii ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f5/8d/81/912666dff82a923ce423a7e797cd75f54271c7031512cdb282\n","Successfully built keras-sequential-ascii\n","Installing collected packages: keras-sequential-ascii\n","Successfully installed keras-sequential-ascii-0.1.1\n"],"name":"stdout"}]},{"metadata":{"id":"XHSELEsYdyNj","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.constraints import maxnorm\n","from keras.optimizers import SGD\n","from keras.layers import Activation\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","from keras_sequential_ascii import sequential_model_to_ascii_printout\n","from keras import backend as K\n","if K.backend()=='tensorflow':\n","    K.set_image_dim_ordering(\"th\")\n","\n","# Import TensorFlow\n","import tensorflow as tf\n","import multiprocessing as mp\n"," \n","# Loading the CIFAR-10 datasets\n","from keras.datasets import cifar10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"diB8eUM-eW0m","colab_type":"code","colab":{}},"cell_type":"code","source":["# Declare variables\n"," \n","batch_size = 32 \n","# 32 examples in a mini-batch, smaller batch size means more updates in one epoch\n"," \n","num_classes = 10\n","data_augmentation = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pjwKcWjFi59y","colab_type":"code","colab":{}},"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data() "],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Dg4efk9i9s1","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convert and Preprocessing\n","\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","y_test = np_utils.to_categorical(y_test, num_classes)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train  /= 255\n","x_test /= 255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZgLsty3fjFl8","colab_type":"code","colab":{}},"cell_type":"code","source":["def base_model():\n"," \n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(32,(3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n"," \n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3,3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n"," \n","    model.add(Flatten())\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes))\n","    model.add(Activation('softmax'))\n"," \n","    sgd = SGD(lr = 0.1, decay=1e-6, nesterov=True)\n","  \n","# Train Model\n"," \n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    return model\n","  \n","cnn_n = base_model()\n","cnn_n.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JmntSEeuaODy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fit model, 20 epochs\n"," \n","cnn_20 = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=20, validation_data=(x_test,y_test),shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W_M9DZGmja9T","colab_type":"code","colab":{}},"cell_type":"code","source":["# Vizualizing model structure\n"," \n","sequential_model_to_ascii_printout(cnn_n)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xi-BqfmMjcS6","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plots for training and testing process: loss and accuracy\n"," \n","plt.figure(0)\n","plt.plot(cnn.history['acc'],'r')\n","plt.plot(cnn.history['val_acc'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training Accuracy vs Validation Accuracy\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.figure(1)\n","plt.plot(cnn.history['loss'],'r')\n","plt.plot(cnn.history['val_loss'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training Loss vs Validation Loss\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mBCz1cHTjhla","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","Y_pred = cnn_n.predict(x_test, verbose=2)\n","y_pred = np.argmax(Y_pred, axis=1)\n"," \n","for ix in range(10):\n","    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n","cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n","print(cm)\n"," \n","# Visualizing of confusion matrix\n","import seaborn as sn\n","import pandas  as pd\n"," \n"," \n","df_cm = pd.DataFrame(cm, range(10),\n","                  range(10))\n","plt.figure(figsize = (10,7))\n","sn.set(font_scale=1.4)#for label size\n","sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5VaFusEsaRr3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fit model, 50 epochs\n"," \n","cnn_50 = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=50, validation_data=(x_test,y_test),shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qyY_MkLxaZmM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Vizualizing model structure\n"," \n","sequential_model_to_ascii_printout(cnn_n)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"90qCbr7Waa5F","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plots for training and testing process: loss and accuracy\n"," \n","plt.figure(0)\n","plt.plot(cnn.history['acc'],'r')\n","plt.plot(cnn.history['val_acc'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training Accuracy vs Validation Accuracy\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.figure(1)\n","plt.plot(cnn.history['loss'],'r')\n","plt.plot(cnn.history['val_loss'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training Loss vs Validation Loss\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8sSlzXWUaeA1","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","Y_pred = cnn_n.predict(x_test, verbose=2)\n","y_pred = np.argmax(Y_pred, axis=1)\n"," \n","for ix in range(10):\n","    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n","cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n","print(cm)\n"," \n","# Visualizing of confusion matrix\n","import seaborn as sn\n","import pandas  as pd\n"," \n"," \n","df_cm = pd.DataFrame(cm, range(10),\n","                  range(10))\n","plt.figure(figsize = (10,7))\n","sn.set(font_scale=1.4)#for label size\n","sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ElxOMFsfaen5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fit model, 100 epochs\n"," \n","cnn_50 = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=100, validation_data=(x_test,y_test),shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qK2jUWQuahxq","colab_type":"code","colab":{}},"cell_type":"code","source":["# Vizualizing model structure\n"," \n","sequential_model_to_ascii_printout(cnn_n)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ufOTBVtDajS3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plots for training and testing process: loss and accuracy\n"," \n","plt.figure(0)\n","plt.plot(cnn.history['acc'],'r')\n","plt.plot(cnn.history['val_acc'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training Accuracy vs Validation Accuracy\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.figure(1)\n","plt.plot(cnn.history['loss'],'r')\n","plt.plot(cnn.history['val_loss'],'g')\n","plt.xticks(np.arange(0, 101, 2.0))\n","plt.rcParams['figure.figsize'] = (8, 6)\n","plt.xlabel(\"Num of Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training Loss vs Validation Loss\")\n","plt.legend(['train','validation'])\n"," \n"," \n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qe7h2cihakTq","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","Y_pred = cnn_n.predict(x_test, verbose=2)\n","y_pred = np.argmax(Y_pred, axis=1)\n"," \n","for ix in range(10):\n","    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n","cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n","print(cm)\n"," \n","# Visualizing of confusion matrix\n","import seaborn as sn\n","import pandas  as pd\n"," \n"," \n","df_cm = pd.DataFrame(cm, range(10),\n","                  range(10))\n","plt.figure(figsize = (10,7))\n","sn.set(font_scale=1.4)#for label size\n","sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n","plt.show()"],"execution_count":0,"outputs":[]}]}